{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with the Keras API and Tensorflow following this YouTube course https://www.youtube.com/watch?v=qFJeN9V1ZsI sponsored or created by https://deeplizard.com/  This is definitely a very good introduction course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets: 1 = experienced side effects, 2 = did not experience side effects\n",
    "# 5% of younger people experienced side effects, 5% of older people did not experience side effects\n",
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, input_shape=(1,), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 0s - loss: 0.7083 - accuracy: 0.4990\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6757 - accuracy: 0.8386\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.6492 - accuracy: 0.8810\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.6227 - accuracy: 0.8705\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5957 - accuracy: 0.8810\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.5675 - accuracy: 0.8986\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.5382 - accuracy: 0.9014\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.5084 - accuracy: 0.9029\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.4793 - accuracy: 0.9138\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.4521 - accuracy: 0.9090\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.4273 - accuracy: 0.9219\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.4051 - accuracy: 0.9248\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3854 - accuracy: 0.9148\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3685 - accuracy: 0.9243\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.3542 - accuracy: 0.9267\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.3417 - accuracy: 0.9281\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.3314 - accuracy: 0.9267\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.3227 - accuracy: 0.9310\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.3152 - accuracy: 0.9305\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.3089 - accuracy: 0.9305\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.3036 - accuracy: 0.9324\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2991 - accuracy: 0.9314\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2953 - accuracy: 0.9305\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2920 - accuracy: 0.9338\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2890 - accuracy: 0.9324\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2865 - accuracy: 0.9329\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2841 - accuracy: 0.9324\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2820 - accuracy: 0.9400\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2802 - accuracy: 0.9343\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2787 - accuracy: 0.9338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c64c6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(1, 16) dtype=float32, numpy=\n",
       " array([[-0.04694164, -0.56716174, -0.46989352, -0.2583939 , -0.0154072 ,\n",
       "          0.27282512,  0.5120504 ,  0.18836603,  0.5401668 ,  0.5170204 ,\n",
       "         -0.06415027,  0.588311  , -0.14476427, -0.4193947 , -0.15595095,\n",
       "          0.5465754 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.08707511, -0.14362608,  0.01429002,  0.18954526,  0.04679232,\n",
       "         0.        , -0.12570624,  0.20405161,  0.        ,  0.18180096,\n",
       "        -0.11939781], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(16, 32) dtype=float32, numpy=\n",
       " array([[ 1.88359588e-01, -2.26399302e-02,  5.73098660e-05,\n",
       "         -8.48396719e-02, -2.33468249e-01, -2.15860903e-02,\n",
       "         -2.80219465e-01, -2.86832750e-01,  2.57203251e-01,\n",
       "          6.49997890e-02,  2.64583856e-01,  3.09833795e-01,\n",
       "          2.10909039e-01, -3.09244484e-01,  3.76879573e-02,\n",
       "          1.17713183e-01,  3.37450594e-01, -2.39864796e-01,\n",
       "         -5.07378876e-02, -2.60809422e-01, -3.27935845e-01,\n",
       "          2.48185992e-02, -1.54392242e-01,  2.10335940e-01,\n",
       "         -1.71065032e-01, -2.66970783e-01,  2.06687540e-01,\n",
       "         -1.46672294e-01, -2.71820873e-01,  1.75865799e-01,\n",
       "         -1.28533393e-01,  2.14328438e-01],\n",
       "        [-1.91757083e-02, -3.76564264e-02,  2.33611614e-01,\n",
       "         -3.20289314e-01,  3.28133374e-01,  1.43316299e-01,\n",
       "          8.86102021e-02, -1.91419095e-01, -1.61615804e-01,\n",
       "          2.82274216e-01, -2.17461586e-03,  1.35769904e-01,\n",
       "          2.17449635e-01, -2.39594370e-01, -1.09647557e-01,\n",
       "         -1.54754296e-01,  1.76855654e-01,  1.88598633e-02,\n",
       "          2.99581796e-01,  1.54888123e-01, -2.24539950e-01,\n",
       "         -1.77173376e-01,  2.08855361e-01,  3.06721658e-01,\n",
       "         -1.28675163e-01,  2.22445160e-01, -7.23689198e-02,\n",
       "         -1.46788120e-01,  2.71133453e-01,  3.46855432e-01,\n",
       "          1.34010375e-01, -1.36341602e-01],\n",
       "        [-6.35343492e-02,  3.19373459e-01,  3.03957313e-01,\n",
       "         -7.27975667e-02,  3.22530180e-01, -1.31131485e-01,\n",
       "          1.28782630e-01, -1.31887093e-01,  3.05087537e-01,\n",
       "         -1.35393441e-02, -2.72793531e-01, -3.40800673e-01,\n",
       "         -6.93791211e-02,  2.47722656e-01,  1.80898756e-01,\n",
       "          6.38912618e-02,  3.03372830e-01,  2.89780825e-01,\n",
       "          5.49792051e-02,  3.63290310e-05,  2.31135935e-01,\n",
       "          2.80443877e-01, -1.66323096e-01,  1.86827272e-01,\n",
       "          6.70426488e-02, -2.04554588e-01, -1.82932407e-01,\n",
       "          2.41445005e-02,  2.89321095e-01, -1.02672160e-01,\n",
       "         -3.39444131e-01, -1.05861083e-01],\n",
       "        [ 2.02923983e-01,  6.92086518e-02, -1.33242026e-01,\n",
       "          1.09579951e-01, -3.64517272e-02,  2.53088087e-01,\n",
       "          1.35546863e-01, -5.33519387e-02,  3.45417589e-01,\n",
       "         -3.01182389e-01,  4.03747559e-02,  1.52620375e-02,\n",
       "         -2.03571558e-01,  3.00272614e-01,  1.05617553e-01,\n",
       "         -2.82252431e-02,  3.06663066e-01,  6.23604059e-02,\n",
       "          2.30942994e-01,  2.42988378e-01,  2.57332057e-01,\n",
       "         -1.83592930e-01,  1.38474137e-01,  3.33643109e-01,\n",
       "          1.34298235e-01, -3.39909762e-01,  2.96573788e-01,\n",
       "          2.63638794e-02, -2.68195301e-01, -1.86043262e-01,\n",
       "         -4.01439369e-02,  4.60262001e-02],\n",
       "        [-1.55866802e-01, -1.06476337e-01,  2.27919728e-01,\n",
       "         -1.29819885e-01,  1.74888521e-01,  1.74469978e-01,\n",
       "          9.61246490e-02,  7.47347176e-02, -3.07686329e-02,\n",
       "          1.38013661e-01, -3.34103048e-01, -2.05172122e-01,\n",
       "          1.29345983e-01, -1.55077562e-01, -2.83219069e-01,\n",
       "         -4.88485396e-02, -2.35095114e-01, -2.87555397e-01,\n",
       "         -1.01537824e-01,  4.29405570e-02, -3.10254395e-01,\n",
       "          3.30928177e-01,  2.79197067e-01,  2.11236030e-01,\n",
       "          1.84027225e-01,  3.00825804e-01,  2.01503426e-01,\n",
       "          2.41097659e-01, -8.78654718e-02, -8.39918852e-03,\n",
       "          2.25203842e-01,  1.38226151e-01],\n",
       "        [ 8.93507823e-02, -3.37069422e-01, -9.23817530e-02,\n",
       "         -1.22052766e-01, -5.60450852e-01, -2.51527667e-01,\n",
       "         -1.39583245e-01,  8.23345482e-02, -7.55162835e-02,\n",
       "         -4.91993785e-01,  1.61273554e-01,  2.80525088e-02,\n",
       "         -3.97638023e-01,  2.25983888e-01,  6.42483354e-01,\n",
       "         -9.61426795e-02,  3.04953396e-01, -6.81823939e-02,\n",
       "          3.15534323e-01, -2.01916173e-01, -2.37810552e-01,\n",
       "          1.57505482e-01,  3.20938528e-01,  1.89623326e-01,\n",
       "         -6.17186308e-01, -1.76801637e-01,  3.48565280e-02,\n",
       "          1.14303946e-01, -2.99506038e-01, -2.34749511e-01,\n",
       "          4.81851369e-01, -1.03237689e-01],\n",
       "        [ 1.46105677e-01, -9.75433290e-02, -6.25963509e-02,\n",
       "          1.73601419e-01, -6.14706933e-01,  2.14368999e-02,\n",
       "         -1.18296951e-01,  1.98077768e-01, -1.10969402e-01,\n",
       "         -2.58694321e-01,  1.44032434e-01, -2.53928602e-01,\n",
       "         -5.54008245e-01, -3.26082140e-01,  1.95679650e-01,\n",
       "         -2.47528344e-01, -1.51303271e-02,  2.54843801e-01,\n",
       "          7.05583692e-02, -3.69265884e-01, -3.50289047e-04,\n",
       "          3.13969046e-01,  4.58572805e-01, -3.94681990e-02,\n",
       "         -2.55982250e-01, -2.79768497e-01, -3.23283672e-01,\n",
       "         -3.25580955e-01,  2.43565947e-01, -2.26083398e-03,\n",
       "          2.97285646e-01, -6.14186525e-02],\n",
       "        [ 2.90382057e-01, -1.62715822e-01,  2.04621688e-01,\n",
       "          1.51087055e-02,  1.11907668e-01,  1.52341396e-01,\n",
       "          2.74558276e-01,  2.65438646e-01, -3.62771028e-03,\n",
       "          5.58861867e-02, -3.38661611e-01,  8.02491009e-02,\n",
       "         -3.14639449e-01, -9.20471251e-02,  7.78965577e-02,\n",
       "         -3.44140559e-01,  2.60438979e-01, -2.70602435e-01,\n",
       "         -3.45701098e-01, -3.05015981e-01, -4.10059750e-01,\n",
       "          1.04261041e-02, -4.29240130e-02, -3.43160033e-01,\n",
       "          2.91959107e-01,  3.45611840e-01, -3.05569947e-01,\n",
       "          1.16394341e-01,  2.55516410e-01, -9.95138288e-03,\n",
       "          3.79370868e-01, -3.46373826e-01],\n",
       "        [-3.25820029e-01, -3.31041664e-01, -7.21930414e-02,\n",
       "         -2.10187465e-01,  6.71465322e-02, -2.89934337e-01,\n",
       "         -1.10528111e-01, -3.29885572e-01,  4.68729623e-02,\n",
       "          2.50582784e-01, -1.04335561e-01, -1.53671011e-01,\n",
       "          4.54256460e-02, -3.00529778e-01, -3.81025672e-02,\n",
       "         -2.20763415e-01, -2.25108620e-02,  8.32405835e-02,\n",
       "         -1.30881727e-01,  3.01413178e-01,  4.61157076e-02,\n",
       "         -1.96069241e-01,  5.03121495e-01,  6.89943060e-02,\n",
       "         -1.99905053e-01,  1.20751694e-01, -2.67068893e-01,\n",
       "         -2.73593813e-01, -9.60893333e-02, -9.13658738e-03,\n",
       "          5.11576593e-01, -3.19320530e-01],\n",
       "        [-8.67135823e-03, -3.25941145e-01, -2.03190967e-01,\n",
       "          1.79359600e-01,  2.04260468e-01, -1.58384308e-01,\n",
       "          7.27457479e-02,  2.32553899e-01, -2.59495229e-02,\n",
       "         -1.71822056e-01, -3.23262006e-01, -9.28882211e-02,\n",
       "          1.68876797e-01,  1.35213137e-04,  6.16766155e-01,\n",
       "         -6.19252622e-02, -3.32771659e-01, -2.91660964e-01,\n",
       "          1.25705600e-02,  5.76299019e-02, -2.45426267e-01,\n",
       "          8.08673203e-02,  4.81574357e-01,  2.79637218e-01,\n",
       "          1.50140494e-01, -3.08217168e-01,  1.32643372e-01,\n",
       "          1.86832100e-01, -1.18171684e-01, -7.36469030e-02,\n",
       "          3.50097150e-01, -2.75633126e-01],\n",
       "        [ 1.72134906e-01,  2.84281522e-01, -1.64389983e-01,\n",
       "          2.72133678e-01, -9.31742191e-02,  3.27352881e-02,\n",
       "         -3.34580392e-01, -3.25887352e-01,  3.34417254e-01,\n",
       "         -3.00643146e-01,  4.00957167e-02, -5.92935383e-02,\n",
       "          3.51432472e-01,  3.24533433e-01, -3.33453804e-01,\n",
       "         -2.58346796e-02,  3.08735102e-01,  3.49575549e-01,\n",
       "         -1.59228340e-01, -4.32905555e-02, -9.89055037e-02,\n",
       "          2.53341407e-01, -2.28053048e-01, -3.11865181e-01,\n",
       "         -1.21409893e-02,  2.94631392e-01,  3.29773396e-01,\n",
       "         -2.83660591e-01,  1.49803489e-01,  1.38312131e-01,\n",
       "         -1.02069885e-01, -3.24456543e-01],\n",
       "        [ 3.05805862e-01,  1.60365403e-02, -2.53077894e-01,\n",
       "         -1.89124644e-01, -2.97359526e-01,  4.88070548e-02,\n",
       "         -5.51952183e-01, -2.26669461e-01, -2.09825009e-01,\n",
       "         -4.81674761e-01,  1.45102903e-01,  3.37402791e-01,\n",
       "         -4.92728621e-01, -1.53390929e-01,  6.40031338e-01,\n",
       "          2.69624084e-01,  1.90501958e-01,  1.07136041e-01,\n",
       "         -7.75300562e-02, -4.98485208e-01, -8.59136432e-02,\n",
       "         -2.96313912e-01,  4.88187075e-01, -3.47456396e-01,\n",
       "          9.09743384e-02, -1.70135364e-01, -9.51596498e-02,\n",
       "          2.77068406e-01, -2.95529217e-01, -3.30704242e-01,\n",
       "          5.72256625e-01,  3.06611389e-01],\n",
       "        [-6.00594953e-02, -1.14760131e-01,  5.47471523e-01,\n",
       "         -3.32654119e-01,  6.85532987e-01, -3.64099145e-02,\n",
       "          6.97238505e-01,  1.89357311e-01,  2.06917524e-01,\n",
       "          4.65651661e-01, -2.25021094e-01,  1.28007412e-01,\n",
       "          5.90124846e-01, -2.16197312e-01, -3.18417698e-01,\n",
       "          8.54626000e-02, -4.11876440e-02,  2.48393536e-01,\n",
       "          1.12102509e-01,  5.86814642e-01,  5.52166283e-01,\n",
       "         -2.43858784e-01, -1.44459317e-02, -2.83074938e-02,\n",
       "          3.16789091e-01, -9.97141302e-02, -2.75987744e-01,\n",
       "         -8.52670372e-02, -3.95039394e-02,  4.21201289e-02,\n",
       "         -1.30279496e-01, -2.68184870e-01],\n",
       "        [-6.26248121e-02, -1.44565970e-01,  3.36018950e-01,\n",
       "         -2.90660083e-01, -2.87050128e-01,  1.25368744e-01,\n",
       "         -1.32712126e-02,  2.38779992e-01, -3.26933950e-01,\n",
       "          2.00896829e-01,  2.54961044e-01, -1.38327971e-01,\n",
       "          1.86900944e-01,  1.77586526e-01,  1.41463280e-02,\n",
       "          2.91534394e-01,  2.21969992e-01, -1.88655868e-01,\n",
       "          2.62665898e-01,  1.23422325e-01, -3.36324513e-01,\n",
       "         -1.30958945e-01, -2.52402484e-01, -7.18536377e-02,\n",
       "         -2.26759315e-01, -1.96366638e-01,  3.04308534e-03,\n",
       "          2.24002898e-02,  2.94638604e-01, -2.81682312e-01,\n",
       "          1.27634048e-01, -8.60780478e-03],\n",
       "        [ 1.14733176e-02, -2.55954266e-01,  6.11125171e-01,\n",
       "          1.81565925e-01,  3.64430845e-02,  2.32200652e-01,\n",
       "          3.39444548e-01,  1.34717494e-01,  1.25943840e-01,\n",
       "          6.64145947e-01, -1.82867303e-01,  6.68489039e-02,\n",
       "          2.23850831e-01,  2.03918904e-01, -3.98161262e-01,\n",
       "          1.46400273e-01, -7.50836392e-04, -1.02013305e-01,\n",
       "         -2.29849011e-01,  5.29218912e-01,  4.10270065e-01,\n",
       "          2.30811924e-01, -5.42620838e-01, -1.14838712e-01,\n",
       "          3.32924485e-01, -2.33615592e-01,  2.58586854e-01,\n",
       "          7.49194920e-02,  2.86559075e-01, -1.72890753e-01,\n",
       "          6.23308048e-02, -3.21754187e-01],\n",
       "        [-2.77842060e-02,  3.27316016e-01, -2.89466619e-01,\n",
       "          2.28433698e-01, -3.03931981e-01,  1.33505374e-01,\n",
       "         -2.36133561e-01, -2.93601185e-01, -3.59398186e-01,\n",
       "         -2.07454234e-01,  3.05428028e-01, -3.04161996e-01,\n",
       "          9.97121036e-02, -2.06033096e-01,  4.90303695e-01,\n",
       "          7.86549449e-02,  6.84592277e-02, -4.01818566e-02,\n",
       "         -1.04698747e-01, -4.22294289e-01, -6.05500489e-02,\n",
       "         -8.84020030e-02,  3.08349878e-01, -2.56216019e-01,\n",
       "         -4.79336977e-01, -1.79578453e-01,  2.45255381e-01,\n",
       "          3.83028984e-02, -8.53178501e-02,  5.26368618e-02,\n",
       "          6.88085914e-01, -2.56757408e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.03380406,  0.        ,  0.21248746, -0.00670767,  0.22012585,\n",
       "         0.        ,  0.2132367 , -0.02674146, -0.00956746,  0.20062657,\n",
       "        -0.01569012, -0.00732541,  0.20875335,  0.        ,  0.01777622,\n",
       "         0.        , -0.02006359, -0.02921882,  0.        ,  0.18665595,\n",
       "         0.14374   ,  0.        , -0.01594698, -0.02389927,  0.2163764 ,\n",
       "        -0.00054196,  0.        ,  0.        , -0.02414158,  0.        ,\n",
       "        -0.01942302,  0.        ], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(32, 2) dtype=float32, numpy=\n",
       " array([[ 0.35654378, -0.23861468],\n",
       "        [ 0.20513186,  0.20692995],\n",
       "        [ 0.6311759 , -0.8199973 ],\n",
       "        [ 0.12463016, -0.30979848],\n",
       "        [ 0.8095203 , -0.1378111 ],\n",
       "        [-0.37833458, -0.07544529],\n",
       "        [ 0.5369375 , -0.5389789 ],\n",
       "        [-0.17131692,  0.18223822],\n",
       "        [-0.33610615,  0.02739036],\n",
       "        [ 0.50890774, -0.88775414],\n",
       "        [ 0.15361825, -0.09913479],\n",
       "        [-0.34994859, -0.17697072],\n",
       "        [ 0.75676024, -0.28144526],\n",
       "        [ 0.17278495,  0.39457384],\n",
       "        [-0.61806786,  0.7929784 ],\n",
       "        [ 0.16440621, -0.21222712],\n",
       "        [ 0.09760196, -0.1681755 ],\n",
       "        [-0.03233328, -0.36723554],\n",
       "        [-0.00133967,  0.20185998],\n",
       "        [ 0.8692305 , -0.79390985],\n",
       "        [ 0.392657  , -0.6112433 ],\n",
       "        [-0.25603628, -0.28423867],\n",
       "        [-0.4248637 ,  0.3145115 ],\n",
       "        [ 0.04987358,  0.0624912 ],\n",
       "        [ 0.5011998 , -0.70436066],\n",
       "        [-0.3547774 ,  0.12937039],\n",
       "        [-0.2890041 ,  0.3658962 ],\n",
       "        [-0.14101881, -0.04631916],\n",
       "        [ 0.14922583,  0.38834473],\n",
       "        [ 0.34048018,  0.15369818],\n",
       "        [-0.46624342,  0.13842905],\n",
       "        [ 0.1567724 ,  0.07040295]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.01179715, -0.01179715], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_json()  # Architecture only, could also export yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers creating a validation set with keras.  If the accuracy and val_accuracy don't correlate, we may have overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 1s - loss: 0.6353 - accuracy: 0.5566 - val_loss: 0.6309 - val_accuracy: 0.5524\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.6098 - accuracy: 0.6376 - val_loss: 0.6059 - val_accuracy: 0.6524\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.5794 - accuracy: 0.7111 - val_loss: 0.5810 - val_accuracy: 0.6905\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.5515 - accuracy: 0.7476 - val_loss: 0.5578 - val_accuracy: 0.7095\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.5239 - accuracy: 0.7767 - val_loss: 0.5346 - val_accuracy: 0.7286\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.4963 - accuracy: 0.8153 - val_loss: 0.5119 - val_accuracy: 0.7714\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.4691 - accuracy: 0.8323 - val_loss: 0.4894 - val_accuracy: 0.7952\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.4428 - accuracy: 0.8545 - val_loss: 0.4684 - val_accuracy: 0.8095\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.4183 - accuracy: 0.8741 - val_loss: 0.4496 - val_accuracy: 0.8238\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.3960 - accuracy: 0.8910 - val_loss: 0.4329 - val_accuracy: 0.8429\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.3759 - accuracy: 0.8974 - val_loss: 0.4185 - val_accuracy: 0.8571\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.3582 - accuracy: 0.9037 - val_loss: 0.4057 - val_accuracy: 0.8857\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.3430 - accuracy: 0.9138 - val_loss: 0.3955 - val_accuracy: 0.8857\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.3300 - accuracy: 0.9164 - val_loss: 0.3866 - val_accuracy: 0.8952\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.3187 - accuracy: 0.9254 - val_loss: 0.3795 - val_accuracy: 0.8952\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.3091 - accuracy: 0.9286 - val_loss: 0.3735 - val_accuracy: 0.8952\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.3012 - accuracy: 0.9317 - val_loss: 0.3688 - val_accuracy: 0.9048\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2948 - accuracy: 0.9339 - val_loss: 0.3651 - val_accuracy: 0.9048\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2893 - accuracy: 0.9381 - val_loss: 0.3624 - val_accuracy: 0.9048\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2844 - accuracy: 0.9397 - val_loss: 0.3607 - val_accuracy: 0.9048\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2806 - accuracy: 0.9354 - val_loss: 0.3582 - val_accuracy: 0.9048\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2772 - accuracy: 0.9392 - val_loss: 0.3565 - val_accuracy: 0.9048\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2742 - accuracy: 0.9397 - val_loss: 0.3555 - val_accuracy: 0.9048\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2715 - accuracy: 0.9418 - val_loss: 0.3540 - val_accuracy: 0.9095\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2693 - accuracy: 0.9444 - val_loss: 0.3534 - val_accuracy: 0.9095\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2674 - accuracy: 0.9429 - val_loss: 0.3528 - val_accuracy: 0.9095\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2654 - accuracy: 0.9429 - val_loss: 0.3519 - val_accuracy: 0.9095\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2638 - accuracy: 0.9439 - val_loss: 0.3512 - val_accuracy: 0.9095\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2623 - accuracy: 0.9455 - val_loss: 0.3511 - val_accuracy: 0.9095\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2609 - accuracy: 0.9444 - val_loss: 0.3505 - val_accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cd2d4f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_validation = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, input_shape=(1,), activation='softmax')\n",
    "])\n",
    "model_with_validation.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_with_validation.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n",
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_with_validation.predict(x=scaled_test_samples, batch_size=10, verbose=0) # Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5893243  0.41067576]\n",
      "[0.9507733  0.04922668]\n",
      "[0.95306885 0.0469312 ]\n",
      "[0.42410484 0.57589513]\n",
      "[0.9612331  0.03876689]\n",
      "[0.7098934  0.29010656]\n",
      "[0.65204024 0.34795976]\n",
      "[0.01699143 0.98300856]\n",
      "[0.52356386 0.4764361 ]\n",
      "[0.9612888  0.03871119]\n",
      "[0.05954698 0.94045305]\n",
      "[0.7098934  0.29010656]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.9595372  0.04046283]\n",
      "[0.94560933 0.05439071]\n",
      "[0.96057224 0.03942782]\n",
      "[0.04075573 0.95924425]\n",
      "[0.9612702  0.03872975]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.30161068 0.69838935]\n",
      "[0.02027196 0.97972804]\n",
      "[0.3304355 0.6695644]\n",
      "[0.933574   0.06642599]\n",
      "[0.08169861 0.9183014 ]\n",
      "[0.7616439 0.2383561]\n",
      "[0.4569762  0.54302377]\n",
      "[0.95306885 0.0469312 ]\n",
      "[0.96121454 0.03878548]\n",
      "[0.30161068 0.69838935]\n",
      "[0.9613444  0.03865558]\n",
      "[0.14509478 0.85490525]\n",
      "[0.65204024 0.34795976]\n",
      "[0.27427045 0.7257296 ]\n",
      "[0.960673   0.03932698]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.8765917 0.1234083]\n",
      "[0.9131867  0.08681325]\n",
      "[0.9568168  0.04318317]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.30161068 0.69838935]\n",
      "[0.8266378  0.17336217]\n",
      "[0.02638478 0.97361517]\n",
      "[0.05954698 0.94045305]\n",
      "[0.8616224  0.13837764]\n",
      "[0.1293152  0.87068486]\n",
      "[0.8901321  0.10986786]\n",
      "[0.02027196 0.97972804]\n",
      "[0.96136296 0.03863705]\n",
      "[0.04075573 0.95924425]\n",
      "[0.3304355 0.6695644]\n",
      "[0.0287962 0.9712038]\n",
      "[0.8901321  0.10986786]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.2020818 0.7979182]\n",
      "[0.9131867  0.08681325]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.9550607 0.0449392]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.9507733  0.04922668]\n",
      "[0.5893243  0.41067576]\n",
      "[0.5893243  0.41067576]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.27427045 0.7257296 ]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.9216076  0.07839239]\n",
      "[0.8449339  0.15506604]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.9612517  0.03874833]\n",
      "[0.96057224 0.03942782]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.95306885 0.0469312 ]\n",
      "[0.9608739  0.03912606]\n",
      "[0.30161068 0.69838935]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.8901321  0.10986786]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.3304355 0.6695644]\n",
      "[0.960673   0.03932698]\n",
      "[0.933574   0.06642599]\n",
      "[0.96136296 0.03863705]\n",
      "[0.9381588  0.06184117]\n",
      "[0.27427045 0.7257296 ]\n",
      "[0.65204024 0.34795976]\n",
      "[0.9612331  0.03876689]\n",
      "[0.04075573 0.95924425]\n",
      "[0.01423408 0.98576593]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.94560933 0.05439071]\n",
      "[0.94837165 0.05162833]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.9595372  0.04046283]\n",
      "[0.0221374 0.9778626]\n",
      "[0.4569762  0.54302377]\n",
      "[0.02027196 0.97972804]\n",
      "[0.01555273 0.98444724]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.52356386 0.4764361 ]\n",
      "[0.14509478 0.85490525]\n",
      "[0.9595372  0.04046283]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.96057224 0.03942782]\n",
      "[0.9613444  0.03865558]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.9216076  0.07839239]\n",
      "[0.9612517  0.03874833]\n",
      "[0.9582108  0.04178915]\n",
      "[0.04473651 0.9552635 ]\n",
      "[0.3304355 0.6695644]\n",
      "[0.928062 0.071938]\n",
      "[0.04913891 0.9508611 ]\n",
      "[0.04473651 0.9552635 ]\n",
      "[0.01699143 0.98300856]\n",
      "[0.2020818 0.7979182]\n",
      "[0.55669236 0.44330764]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.27427045 0.7257296 ]\n",
      "[0.18142001 0.81858   ]\n",
      "[0.8901321  0.10986786]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.01555273 0.98444724]\n",
      "[0.960673   0.03932698]\n",
      "[0.4569762  0.54302377]\n",
      "[0.49022675 0.50977325]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.65204024 0.34795976]\n",
      "[0.05954698 0.94045305]\n",
      "[0.05954698 0.94045305]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.01555273 0.98444724]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.9601851  0.03981487]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.01555273 0.98444724]\n",
      "[0.9023524  0.09764763]\n",
      "[0.02027196 0.97972804]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.08169861 0.9183014 ]\n",
      "[0.30161068 0.69838935]\n",
      "[0.42410484 0.57589513]\n",
      "[0.16244052 0.83755946]\n",
      "[0.9216076  0.07839239]\n",
      "[0.8901321  0.10986786]\n",
      "[0.94837165 0.05162833]\n",
      "[0.8449339  0.15506604]\n",
      "[0.960673   0.03932698]\n",
      "[0.7098934  0.29010656]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.8449339  0.15506604]\n",
      "[0.9612888  0.03871119]\n",
      "[0.0287962 0.9712038]\n",
      "[0.960974   0.03902598]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.9420634  0.05793667]\n",
      "[0.9568168  0.04318317]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.05954698 0.94045305]\n",
      "[0.9612888  0.03871119]\n",
      "[0.04913891 0.9508611 ]\n",
      "[0.94837165 0.05162833]\n",
      "[0.961367   0.03863299]\n",
      "[0.96136296 0.03863705]\n",
      "[0.960673   0.03932698]\n",
      "[0.09117572 0.90882427]\n",
      "[0.9607735 0.0392264]\n",
      "[0.78501534 0.21498461]\n",
      "[0.96132594 0.0386741 ]\n",
      "[0.02417026 0.9758297 ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.03738134 0.9626186 ]\n",
      "[0.49022675 0.50977325]\n",
      "[0.05954698 0.94045305]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.16244052 0.83755946]\n",
      "[0.9216076  0.07839239]\n",
      "[0.960974   0.03902598]\n",
      "[0.01699143 0.98300856]\n",
      "[0.9612888  0.03871119]\n",
      "[0.01423408 0.98576593]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.9381588  0.06184117]\n",
      "[0.01699143 0.98300856]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.08169861 0.9183014 ]\n",
      "[0.0287962 0.9712038]\n",
      "[0.7616439 0.2383561]\n",
      "[0.3918914  0.60810864]\n",
      "[0.9601851  0.03981487]\n",
      "[0.96130735 0.03869265]\n",
      "[0.8765917 0.1234083]\n",
      "[0.5893243  0.41067576]\n",
      "[0.9610738  0.03892612]\n",
      "[0.96132594 0.0386741 ]\n",
      "[0.04473651 0.9552635 ]\n",
      "[0.02638478 0.97361517]\n",
      "[0.0221374 0.9778626]\n",
      "[0.02417026 0.9758297 ]\n",
      "[0.9612702  0.03872975]\n",
      "[0.27427045 0.7257296 ]\n",
      "[0.9601851  0.03981487]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.02638478 0.97361517]\n",
      "[0.01699143 0.98300856]\n",
      "[0.01555273 0.98444724]\n",
      "[0.10212123 0.8978787 ]\n",
      "[0.18142001 0.81858   ]\n",
      "[0.02638478 0.97361517]\n",
      "[0.0221374 0.9778626]\n",
      "[0.9595372  0.04046283]\n",
      "[0.55669236 0.44330764]\n",
      "[0.96136296 0.03863705]\n",
      "[0.01555273 0.98444724]\n",
      "[0.94837165 0.05162833]\n",
      "[0.05954698 0.94045305]\n",
      "[0.96136296 0.03863705]\n",
      "[0.1293152  0.87068486]\n",
      "[0.9612888  0.03871119]\n",
      "[0.9023524  0.09764763]\n",
      "[0.9381588  0.06184117]\n",
      "[0.30161068 0.69838935]\n",
      "[0.96121454 0.03878548]\n",
      "[0.9131867  0.08681325]\n",
      "[0.02638478 0.97361517]\n",
      "[0.02027196 0.97972804]\n",
      "[0.68166685 0.31833312]\n",
      "[0.1293152  0.87068486]\n",
      "[0.02027196 0.97972804]\n",
      "[0.9568168  0.04318317]\n",
      "[0.7098934  0.29010656]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.04913891 0.9508611 ]\n",
      "[0.03738134 0.9626186 ]\n",
      "[0.65204024 0.34795976]\n",
      "[0.16244052 0.83755946]\n",
      "[0.9595372  0.04046283]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.9588791  0.04112087]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.09117572 0.90882427]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.9420634  0.05793667]\n",
      "[0.9612517  0.03874833]\n",
      "[0.9381588  0.06184117]\n",
      "[0.30161068 0.69838935]\n",
      "[0.9381588  0.06184117]\n",
      "[0.2020818 0.7979182]\n",
      "[0.16244052 0.83755946]\n",
      "[0.1293152  0.87068486]\n",
      "[0.96130735 0.03869265]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.96136296 0.03863705]\n",
      "[0.5893243  0.41067576]\n",
      "[0.02027196 0.97972804]\n",
      "[0.9612331  0.03876689]\n",
      "[0.01423408 0.98576593]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.04075573 0.95924425]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.3304355 0.6695644]\n",
      "[0.04075573 0.95924425]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.8266378  0.17336217]\n",
      "[0.96121454 0.03878548]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.96130735 0.03869265]\n",
      "[0.94837165 0.05162833]\n",
      "[0.05954698 0.94045305]\n",
      "[0.08169861 0.9183014 ]\n",
      "[0.05954698 0.94045305]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.7616439 0.2383561]\n",
      "[0.960974   0.03902598]\n",
      "[0.01423408 0.98576593]\n",
      "[0.9612702  0.03872975]\n",
      "[0.9612702  0.03872975]\n",
      "[0.65204024 0.34795976]\n",
      "[0.02417026 0.9758297 ]\n",
      "[0.9420634  0.05793667]\n",
      "[0.9612517  0.03874833]\n",
      "[0.96130735 0.03869265]\n",
      "[0.96057224 0.03942782]\n",
      "[0.01555273 0.98444724]\n",
      "[0.30161068 0.69838935]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.7098934  0.29010656]\n",
      "[0.9612331  0.03876689]\n",
      "[0.10212123 0.8978787 ]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.55669236 0.44330764]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.9613444  0.03865558]\n",
      "[0.3304355 0.6695644]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.8765917 0.1234083]\n",
      "[0.01555273 0.98444724]\n",
      "[0.01423408 0.98576593]\n",
      "[0.96136296 0.03863705]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.78501534 0.21498461]\n",
      "[0.3304355 0.6695644]\n",
      "[0.80667686 0.1933231 ]\n",
      "[0.02638478 0.97361517]\n",
      "[0.0221374 0.9778626]\n",
      "[0.96130735 0.03869265]\n",
      "[0.96136296 0.03863705]\n",
      "[0.62118846 0.37881154]\n",
      "[0.03738134 0.9626186 ]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.8901321  0.10986786]\n",
      "[0.9612702  0.03872975]\n",
      "[0.8901321  0.10986786]\n",
      "[0.96132594 0.0386741 ]\n",
      "[0.62118846 0.37881154]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.0287962 0.9712038]\n",
      "[0.9595372  0.04046283]\n",
      "[0.960974   0.03902598]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.11502083 0.8849792 ]\n",
      "[0.01423408 0.98576593]\n",
      "[0.65204024 0.34795976]\n",
      "[0.96121454 0.03878548]\n",
      "[0.9613444  0.03865558]\n",
      "[0.3304355 0.6695644]\n",
      "[0.16244052 0.83755946]\n",
      "[0.7098934  0.29010656]\n",
      "[0.9381588  0.06184117]\n",
      "[0.02417026 0.9758297 ]\n",
      "[0.9595372  0.04046283]\n",
      "[0.9507733  0.04922668]\n",
      "[0.05395003 0.94605   ]\n",
      "[0.7616439 0.2383561]\n",
      "[0.933574   0.06642599]\n",
      "[0.9611735  0.03882653]\n",
      "[0.9550607 0.0449392]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.5893243  0.41067576]\n",
      "[0.55669236 0.44330764]\n",
      "[0.8616224  0.13837764]\n",
      "[0.95306885 0.0469312 ]\n",
      "[0.08169861 0.9183014 ]\n",
      "[0.04473651 0.9552635 ]\n",
      "[0.960974   0.03902598]\n",
      "[0.03142089 0.9685791 ]\n",
      "[0.9612331  0.03876689]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.02027196 0.97972804]\n",
      "[0.42410484 0.57589513]\n",
      "[0.9381588  0.06184117]\n",
      "[0.9601851  0.03981487]\n",
      "[0.9601851  0.03981487]\n",
      "[0.78501534 0.21498461]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.961367   0.03863299]\n",
      "[0.9550607 0.0449392]\n",
      "[0.9216076  0.07839239]\n",
      "[0.02417026 0.9758297 ]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.22445175 0.7755483 ]\n",
      "[0.04075573 0.95924425]\n",
      "[0.960974   0.03902598]\n",
      "[0.10212123 0.8978787 ]\n",
      "[0.01423408 0.98576593]\n",
      "[0.9420634  0.05793667]\n",
      "[0.8765917 0.1234083]\n",
      "[0.9611735  0.03882653]\n",
      "[0.09117572 0.90882427]\n",
      "[0.9550607 0.0449392]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.78501534 0.21498461]\n",
      "[0.06616279 0.9338372 ]\n",
      "[0.01856073 0.9814393 ]\n",
      "[0.9612517  0.03874833]\n",
      "[0.04913891 0.9508611 ]\n",
      "[0.9612888  0.03871119]\n",
      "[0.94560933 0.05439071]\n",
      "[0.961367   0.03863299]\n",
      "[0.36059287 0.6394071 ]\n",
      "[0.24852651 0.7514734 ]\n",
      "[0.9381588  0.06184117]\n",
      "[0.03427638 0.9657237 ]\n",
      "[0.0221374 0.9778626]\n",
      "[0.42410484 0.57589513]\n",
      "[0.3918914  0.60810864]\n",
      "[0.96136296 0.03863705]\n",
      "[0.14509478 0.85490525]\n",
      "[0.9216076  0.07839239]\n",
      "[0.96130735 0.03869265]\n",
      "[0.05954698 0.94045305]\n",
      "[0.05954698 0.94045305]\n",
      "[0.928062 0.071938]\n",
      "[0.9612702  0.03872975]\n",
      "[0.04075573 0.95924425]\n",
      "[0.9612517  0.03874833]\n",
      "[0.78501534 0.21498461]\n",
      "[0.16244052 0.83755946]\n",
      "[0.9131867  0.08681325]\n",
      "[0.04913891 0.9508611 ]\n",
      "[0.8266378  0.17336217]\n",
      "[0.9608739  0.03912606]\n",
      "[0.07348592 0.926514  ]\n",
      "[0.9595372  0.04046283]\n",
      "[0.16244052 0.83755946]\n",
      "[0.55669236 0.44330764]\n",
      "[0.96057224 0.03942782]\n",
      "[0.01423408 0.98576593]\n",
      "[0.02027196 0.97972804]\n",
      "[0.49022675 0.50977325]\n",
      "[0.5893243  0.41067576]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix to visualize prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[195  15]\n",
      " [  9 201]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
