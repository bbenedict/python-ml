{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an introductory notebook created to explore O'Reilly Introduction to ML w/Python in the area of linear regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard linear regression as a baseline. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is the coefficient of determination R2 defined as R2 = (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.67008903\n",
      "Test set score: 0.65933686\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set score: {:.8f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.8f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression focusses on regularization (linear least squares with l2 regularization), which is less likely to overfit.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.67005993\n",
      "Test set score: 0.65779469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge10 = Ridge().fit(X_train, y_train)\n",
    "print(\"Train set score: {:.8f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.8f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing alpha decreases the impact of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.67008874\n",
      "Test set score: 0.65918341\n"
     ]
    }
   ],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Train set score: {:.8f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.8f}\".format(ridge01.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression also focusses on regularization (L1 prior as regularizer aka the Lasso) by forcing some theta (coefficients) to zero.  This can lead to underfitting by removing to many features.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.28528831\n",
      "Test set score: 0.23759680\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso10 = Lasso().fit(X_train, y_train)\n",
    "print(\"Train set score: {:.8f}\".format(lasso10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.8f}\".format(lasso10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Ridge, we can decrease alpha to reduce regularization. The number of iterations is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.66624102\n",
      "Test set score: 0.63935113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso01 = Lasso(alpha=0.1,max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Train set score: {:.8f}\".format(lasso01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.8f}\".format(lasso01.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
